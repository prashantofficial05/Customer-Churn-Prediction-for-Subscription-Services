# -*- coding: utf-8 -*-
"""Customer Churn Prediction for Subscription Services.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ms4D4lym3-f9jr2Sa0bCSj4yoo201MtC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
print(data.head())

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score

# Check for columns that do not exist
columns_to_drop = ['customerID', 'gender', 'Partner', 'Dependents', 'PhoneService',
                  'MultipleLines', 'OnlineSecurity', 'OnlineBackup',
                  'DeviceProtection', 'TechSupport', 'StreamingTV',
                  'StreamingMovies', 'Contract', 'PaperlessBilling',
                  'PaymentMethod']

columns_existing = [col for col in columns_to_drop if col in data.columns]
data = data.drop(columns_existing, axis=1)


numerical_cols = data.select_dtypes(include=np.number).columns
data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].mean())

label_encoder = LabelEncoder()
for column in data.columns:
  if data[column].dtype == object:
    data[column] = label_encoder.fit_transform(data[column])

# Scale numerical features
scaler = StandardScaler()
numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
data[numerical_features] = scaler.fit_transform(data[numerical_features])

print(data.head())

data['AvgChargesPerMonth'] = data['TotalCharges'] / (data['tenure'] + 1)
data.drop(['TotalCharges'], axis=1, inplace=True)

x = data.drop('Churn', axis=1)
y = data['Churn']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
y_proba = model.predict_proba(x_test)[:, 1]

#evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC AUC Score :", roc_auc_score(y_test, y_proba))
print("\n Classification Report: \n ", classification_report(y_test, y_pred))

feature_importance = pd.Series(model.feature_importances_, index=x.columns)
feature_importance.nlargest(10).plot(kind='barh', title=" Top 10 Feature Importances")
plt.show()

